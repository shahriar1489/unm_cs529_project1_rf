{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a5e53365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "# Arithmetic \n",
    "import math\n",
    "from fractions import Fraction\n",
    "from decimal import Decimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cacc900e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum occurring index: 66\n",
      "Maximum occurring value: 66\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example column vector\n",
    "column_vector = np.array([1, 2, 3, 2, 2, 4, 5, 2, 66, 66, 66, 66, 66])\n",
    "\n",
    "# Find the index of the maximum occurring value\n",
    "max_index = np.argmax(np.bincount(column_vector))\n",
    "\n",
    "\n",
    "# Get the maximum occurring value\n",
    "max_value = np.bincount(column_vector).argmax()\n",
    "\n",
    "print(\"Maximum occurring index:\", max_index)\n",
    "print(\"Maximum occurring value:\", max_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "bf9fe971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.bincount(column_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b82cc2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\n\\n# Create a NumPy array representing the column vector\\ndata = np.array([222,222,222,222,222,222,222,222, 1, 1, 0, 1, 1, 0, 0, 1])\\n\\n# Find the most frequent target value\\ntarget_value, target_count = np.unique(data, return_counts=True)\\nmost_frequent_value = target_value[np.argmax(target_count)]\\n\\n\\n\\n\\n\\n\\nprint(\"The most frequent value is:\", most_frequent_value)\\n'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "# Create a NumPy array representing the column vector\n",
    "data = np.array([222,222,222,222,222,222,222,222, 1, 1, 0, 1, 1, 0, 0, 1])\n",
    "\n",
    "# Find the most frequent target value\n",
    "target_value, target_count = np.unique(data, return_counts=True)\n",
    "most_frequent_value = target_value[np.argmax(target_count)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"The most frequent value is:\", most_frequent_value)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e7dc9874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "87dcf58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "942fbf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.argmax(label_count) # return index number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1d258894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([[1, 2, 3], \n",
    "                [4, 5, 6]])\n",
    "\n",
    "for row in arr:\n",
    "    for element in row:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1a2c60b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for i in np.array([2, 4, 6, 8]): \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f06559c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_impurity_by_label(attribute, impurity='gini'): # Impurity of the total dataset : DONE\n",
    "        \n",
    "        \"\"\"\n",
    "        FEATURES: \n",
    "        \n",
    "        attribute : pandas df\n",
    "            the column whose entropy is to be calculated\n",
    "        \n",
    "        impurity : string \n",
    "            the impurity measure used- gini or entropty \n",
    "        \n",
    "        \n",
    "        Returns \n",
    "            np real scalar number \n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"--> In method: compute_impurity_by_label \")\n",
    "        # get the total number of instances/rows in the dataset\n",
    "        N = attribute.shape[0]\n",
    "        \n",
    "        print('\\t\\t Number of rows in attribute param:', N)\n",
    "        #sys.exit(0)\n",
    "    \n",
    "        # get the count\n",
    "        label_values, label_counts = np.unique(attribute, return_counts=True)\n",
    "        label_fractions = []\n",
    "    \n",
    "    \n",
    "        # get the fractions for the each of the labels- better to use loop be cause there can be more than two labels\n",
    "    \n",
    "        for count in label_counts :\n",
    "            print(Decimal(count/N)) \n",
    "            \n",
    "            result_float = float( count/ Decimal(N) )\n",
    "            \n",
    "            label_fractions.append( result_float  )\n",
    "    \n",
    "    \n",
    "        print('\\t\\tlabel_fractions: ',label_fractions)\n",
    "        \n",
    "        label_fractions = np.array( label_fractions )\n",
    "        print('\\t\\tDifferent label values collected: ', label_values)\n",
    "        print('\\t\\tDifferent label counts colleceted: ', label_counts)\n",
    "        print('\\t\\tFractions of different labels: ', label_fractions)\n",
    "    \n",
    "    \n",
    "        # write a subroutine for entropy\n",
    "        if impurity=='entropy':\n",
    "            #return  - np.sum ( label_fractions * np.log2(  label_fractions ) ) # This returns the complete entropy \n",
    "            print('-------------\\n\\n\\n')\n",
    "            #print(\"\\t\\t\\tInside impurity=entropy\",  -1 * label_fractions * np.log2(label_fractions) ) \n",
    "    \n",
    "            print(\"-------------\\t\\t\\entropy = \", -np.sum(  label_fractions * np.log2(label_fractions) ) )\n",
    "            \n",
    "            \n",
    "            return -np.sum(  label_fractions * np.log2(label_fractions) )\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "        # write a subroutine for gini\n",
    "        elif impurity=='gini':  \n",
    "    \n",
    "          return 1 - np.sum(  np.square( label_fractions )   ) # 1 - sum of elementwise fraction #This returns the complete gini\n",
    "    \n",
    "    \n",
    "        # write the third metric \n",
    "    \n",
    "    \n",
    "    \n",
    "        else :\n",
    "          print(\"ERROR: impurity metric can be either of gini or entropy.\")\n",
    "          return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "bb88a629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  attribute\n",
      "0         B\n",
      "1         B\n",
      "2         A\n",
      "3         A\n",
      "4         B\n"
     ]
    }
   ],
   "source": [
    "# Define the discrete values\n",
    "discrete_values = ['A', 'B']\n",
    "\n",
    "# Generate the test data\n",
    "test_data = pd.DataFrame({'attribute': np.random.choice(discrete_values, size=100)})\n",
    "\n",
    "print(test_data.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1b53ab80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2bf2a890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['attribute'], dtype='object')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7d79620b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 100\n",
      "0.450000000000000011102230246251565404236316680908203125\n",
      "0.5500000000000000444089209850062616169452667236328125\n",
      "\t\tlabel_fractions:  [0.45, 0.55]\n",
      "\t\tDifferent label values collected:  ['A' 'B']\n",
      "\t\tDifferent label counts colleceted:  [45 55]\n",
      "\t\tFractions of different labels:  [0.45 0.55]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4949999999999999"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_impurity_by_label(test_data, impurity='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "63291a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 100\n",
      "0.450000000000000011102230246251565404236316680908203125\n",
      "0.5500000000000000444089209850062616169452667236328125\n",
      "\t\tlabel_fractions:  [0.45, 0.55]\n",
      "\t\tDifferent label values collected:  ['A' 'B']\n",
      "\t\tDifferent label counts colleceted:  [45 55]\n",
      "\t\tFractions of different labels:  [0.45 0.55]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.9927744539878083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9927744539878083"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_impurity_by_label(test_data, impurity='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "cbdd63c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 70\n",
      "0.85714285714285709527615608749329112470149993896484375\n",
      "0.142857142857142849212692681248881854116916656494140625\n",
      "\t\tlabel_fractions:  [0.8571428571428571, 0.14285714285714285]\n",
      "\t\tDifferent label values collected:  ['A' 'B']\n",
      "\t\tDifferent label counts colleceted:  [60 10]\n",
      "\t\tFractions of different labels:  [0.85714286 0.14285714]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.5916727785823275\n",
      "entropy:\t 0.5916727785823275\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Issues reported in the compute_impurity_by_label method: \n",
    "\n",
    "    i) entropy is returning more than 1 \n",
    "        \n",
    "        - Proposed solution: \n",
    "            - Use a \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define the labels and their counts\n",
    "labels = ['A'] * 60 + ['B'] * 10 \n",
    "\n",
    "# Shuffle the labels to randomize the order\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "# Create a DataFrame with the labels\n",
    "test_data_2 = pd.DataFrame({'attribute': labels})\n",
    "\n",
    "#print(test_data_2.head())\n",
    "\n",
    "\n",
    "print( 'entropy:\\t',compute_impurity_by_label(test_data_2, impurity='entropy') ) \n",
    "#|print( 'gini:\\t', compute_impurity_by_label(test_data_2, impurity='gini') ) \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "cb441368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decimal.Decimal"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( Decimal(60/100) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d2183879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float( Decimal(60/100) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ca55f4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.442182"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.73697 * -.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f941844f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.9182958340544896\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given label counts\n",
    "label_counts = np.array([60,  30])\n",
    "\n",
    "# Total count of labels\n",
    "total_count = np.sum(label_counts)\n",
    "\n",
    "# Calculate probabilities\n",
    "probabilities = label_counts / total_count\n",
    "\n",
    "# Calculate entropy\n",
    "entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "print(\"Entropy:\", entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "73a0dde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card4</th>\n",
       "      <th>card6</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>debit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W</td>\n",
       "      <td>visa</td>\n",
       "      <td>debit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H</td>\n",
       "      <td>visa</td>\n",
       "      <td>debit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W</td>\n",
       "      <td>discover</td>\n",
       "      <td>credit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W</td>\n",
       "      <td>visa</td>\n",
       "      <td>debit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProductCD       card4   card6  isFraud\n",
       "0         C  mastercard   debit        0\n",
       "1         W        visa   debit        0\n",
       "2         H        visa   debit        0\n",
       "3         W    discover  credit        0\n",
       "4         W        visa   debit        0"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_1 = pd.read_csv('test_data_1.csv')\n",
    "\n",
    "test_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "65869d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         C\n",
       "1         W\n",
       "2         H\n",
       "3         W\n",
       "4         W\n",
       "         ..\n",
       "472427    W\n",
       "472428    W\n",
       "472429    W\n",
       "472430    W\n",
       "472431    H\n",
       "Name: ProductCD, Length: 472432, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_1['ProductCD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3d543d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain_for_discrete_attribute(examples_a, target_attribute, impurity='entropy'): # 02/28/2024 This stays. Fix this \n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        examples_a : the attribute column whose feature is to be calculated \n",
    "            type: Pandas Series \n",
    "            \n",
    "        target_attribute : attribute whose value is to be predicted by tree \n",
    "            type: Pandas Series  \n",
    "        \n",
    "        attribute : attribute/column name for examples_a\n",
    "            type: string\n",
    "        \n",
    "        impurity_measure : gini/entropy \n",
    "            type: string\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        scalar real number  \n",
    "            \n",
    "        \n",
    "        \n",
    "        self.information_gain( examples[a], target_attribute, 'entropy') # examples is pd df\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        #impurity_for_target_attribute = self.compute_impurity_for_discrete_attribute(target_attribute, impurity=impurity)\n",
    "        \n",
    "        \n",
    "        # get the unique values in examples_a\n",
    "        examples_a_values = np.unique(examples_a)\n",
    "        \n",
    "        N = examples_a.shape[0]\n",
    "        \n",
    "        result = compute_impurity_by_label(  np.array( target_attribute ), impurity=impurity)\n",
    "        \n",
    "        print( '\\t\\t\\tresult after initialization : ', result) # ok \n",
    "        \n",
    "        #sys.exit(0)\n",
    "        for a in examples_a_values: \n",
    "            \n",
    "            # get the subset of examples_a and corresponding tuple in target_attribute\n",
    "            #examples_a[attribute]\n",
    "            #print( examples_a[examples_a==a])\n",
    "            #print('-----')\n",
    "            #print('feature subset shape:\\n', examples_a[examples_a==a].shape)\n",
    "            #print('-----')\n",
    "            \n",
    "            #print( 'target subset shape:\\n', target_attribute[examples_a==a].shape )\n",
    "        \n",
    "            \n",
    "            #examples_a_subset = np.array( examples_a[examples_a==a] ) \n",
    "            \"\"\"\n",
    "            I don't need the line above rn\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            #target_a_subset = np.array( target_attribute[examples_a==a] ) # converting to np for faster computation\n",
    "            \n",
    "            n = target_attribute[examples_a==a].shape[0]\n",
    "            #compute_impurity_by_label(  np.array( target_attribute[examples_a==a] ), impurity=impurity)\n",
    "            \n",
    "            \n",
    "            prob_float = float( n/ Decimal(N) )\n",
    "            \n",
    "            result = result - ( prob_float *  compute_impurity_by_label(  np.array( target_attribute[examples_a==a] ), impurity=impurity) ) \n",
    "                    \n",
    "            \n",
    "            print('\\t\\t---------------\\t\\t\\n')\n",
    "            #sys.exit(0)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print('\\t\\t\\t--- final info gain : ', result )\n",
    "        return result # returns a scalar real number     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c5fc5963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 472432\n",
      "0.9650108375385240133681463703396730124950408935546875\n",
      "0.034989162461475938059596302309728343971073627471923828125\n",
      "\t\tlabel_fractions:  [0.965010837538524, 0.03498916246147594]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [455902  16530]\n",
      "\t\tFractions of different labels:  [0.96501084 0.03498916]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.21882586530176718\n",
      "\t\t\tresult after initialization :  0.21882586530176718\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 54643\n",
      "0.88269311714217735254095487107406370341777801513671875\n",
      "0.117306882857822591947893897668109275400638580322265625\n",
      "\t\tlabel_fractions:  [0.8826931171421774, 0.11730688285782259]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [48233  6410]\n",
      "\t\tFractions of different labels:  [0.88269312 0.11730688]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.521569715414749\n",
      "\t\t---------------\t\t\n",
      "\n",
      "\t\t\t--- final info gain :  0.15849943957402618\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 26489\n",
      "0.9523575823926913042072328607900999486446380615234375\n",
      "0.0476424176073086957927671392099000513553619384765625\n",
      "\t\tlabel_fractions:  [0.9523575823926913, 0.047642417607308696]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [25227  1262]\n",
      "\t\tFractions of different labels:  [0.95235758 0.04764242]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.2762964223711254\n",
      "\t\t---------------\t\t\n",
      "\n",
      "\t\t\t--- final info gain :  0.1430076525397255\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 30111\n",
      "0.96197402942446286200350868966779671609401702880859375\n",
      "0.03802597057553717962985473377557354979217052459716796875\n",
      "\t\tlabel_fractions:  [0.9619740294244629, 0.03802597057553718]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [28966  1145]\n",
      "\t\tFractions of different labels:  [0.96197403 0.03802597]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.23316695318724723\n",
      "\t\t---------------\t\t\n",
      "\n",
      "\t\t\t--- final info gain :  0.1281464870652843\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 9328\n",
      "0.9433962264150943521912040523602627217769622802734375\n",
      "0.05660377358490566168658375545419403351843357086181640625\n",
      "\t\tlabel_fractions:  [0.9433962264150944, 0.05660377358490566]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [8800  528]\n",
      "\t\tFractions of different labels:  [0.94339623 0.05660377]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.3138129641688651\n",
      "\t\t---------------\t\t\n",
      "\n",
      "\t\t\t--- final info gain :  0.121950362903993\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 351861\n",
      "0.97958000460409078158363627153448760509490966796875\n",
      "0.0204199953959091802524472569757563178427517414093017578125\n",
      "\t\tlabel_fractions:  [0.9795800046040908, 0.02041999539590918]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [344676   7185]\n",
      "\t\tFractions of different labels:  [0.97958 0.02042]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.1437922468945473\n",
      "\t\t---------------\t\t\n",
      "\n",
      "\t\t\t--- final info gain :  0.014855831236869885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.014855831236869885"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain_for_discrete_attribute( test_data_1['ProductCD'], test_data_1['isFraud'], impurity='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "0896d044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['C', 'H', 'R', 'S', 'W'], dtype=object),\n",
       " array([ 54643,  26489,  30111,   9328, 351861]))"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique( test_data_1['ProductCD'], return_counts = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "46f00222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472432"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_1['ProductCD'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a9c8f28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 472432\n",
      "0.9650108375385240133681463703396730124950408935546875\n",
      "0.034989162461475938059596302309728343971073627471923828125\n",
      "\t\tlabel_fractions:  [0.965010837538524, 0.03498916246147594]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [455902  16530]\n",
      "\t\tFractions of different labels:  [0.96501084 0.03498916]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.21882586530176718\n",
      "\t\t\tresult after initialization :  0.21882586530176718\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 1269\n",
      "0.97241922773837663473983639050857163965702056884765625\n",
      "0.0275807722616233270962471380016722832806408405303955078125\n",
      "\t\tlabel_fractions:  [0.9724192277383766, 0.027580772261623327]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [1234   35]\n",
      "\t\tFractions of different labels:  [0.97241923 0.02758077]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.18211053219929707\n",
      "\t\t---------------\t\t\n",
      "\n",
      "\t\t\t--- final info gain :  0.21833669804518652\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 6638\n",
      "0.9713769207592648502469501181622035801410675048828125\n",
      "0.0286230792407351601613907376986389863304793834686279296875\n",
      "\t\tlabel_fractions:  [0.9713769207592649, 0.02862307924073516]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [6448  190]\n",
      "\t\tFractions of different labels:  [0.97137692 0.02862308]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.18743895843937042\n",
      "\t\t---------------\t\t\n",
      "\n",
      "\t\t\t--- final info gain :  0.21570304959182066\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 5350\n",
      "0.9224299065420560328476540234987623989582061767578125\n",
      "0.07757009345794392551898255305786733515560626983642578125\n",
      "\t\tlabel_fractions:  [0.922429906542056, 0.07757009345794393]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [4935  415]\n",
      "\t\tFractions of different labels:  [0.92242991 0.07757009]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.39355885167144466\n",
      "\t\t---------------\t\t\n",
      "\n",
      "\t\t\t--- final info gain :  0.21124623918007415\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 151030\n",
      "0.96580811759253126780322418198920786380767822265625\n",
      "0.034191882407468711380094106289107003249228000640869140625\n",
      "\t\tlabel_fractions:  [0.9658081175925313, 0.03419188240746871]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [145866   5164]\n",
      "\t\tFractions of different labels:  [0.96580812 0.03419188]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.21499674911056593\n",
      "\t\t---------------\t\t\n",
      "\n",
      "\t\t\t--- final info gain :  0.1425147412752566\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 308145\n",
      "0.9651917116941699514853780783596448600292205810546875\n",
      "0.0348082883058300485146219216403551399707794189453125\n",
      "\t\tlabel_fractions:  [0.96519171169417, 0.03480828830583005]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [297419  10726]\n",
      "\t\tFractions of different labels:  [0.96519171 0.03480829]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.21795958016275585\n",
      "\t\t---------------\t\t\n",
      "\n",
      "\t\t\t--- final info gain :  0.0003500385683010976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0003500385683010976"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain_for_discrete_attribute( test_data_1['card4'], test_data_1['isFraud'], impurity='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "cb0f9feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([455902,  16530]))"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique( test_data_1['isFraud'], return_counts=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "8a2c446d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472432"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_1['isFraud'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "7296e8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TransactionID', 'ProductCD', 'card1', 'card2', 'card3', 'card4',\n",
      "       'card5', 'card6', 'addr1', 'addr2', 'TransactionDT', 'TransactionAmt',\n",
      "       'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11',\n",
      "       'C12', 'C13', 'C14', 'isFraud'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_cont_1 = pd.read_csv('train.csv')\n",
    "print( df_cont_1.columns ) \n",
    "\n",
    "df_cont_1 = df_cont_1[['TransactionAmt', 'isFraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "ce06c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_1\n",
    "\n",
    "examples_a = df_cont_1['TransactionAmt']\n",
    "target_attribute = df_cont_1['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "2ebe3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample \n",
    "\n",
    "def sample_continuous_attribute(examples_a,  target_attribute,  sampling_threshold=0.2): \n",
    "    \"\"\"\n",
    "    Paramters: \n",
    "    \n",
    "    - examples_a : pandas series \n",
    "    \n",
    "    - target_attribute : pandas series \n",
    "    \n",
    "    \n",
    "    Notice that column name is passed with pd series \n",
    "    \n",
    "    Returns: \n",
    "    - pandas df with the resampled df of shape (n, 2)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    attribute = examples_a.name\n",
    "    target = target_attribute.name\n",
    "    \n",
    "    print('\\tattribute and target name : ', attribute, ', ', target)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = pd.concat([examples_a, target_attribute], axis=1)\n",
    "    #df.rename(columns[])\n",
    "    print('Columns of new df formed', df.columns)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    I have a pseudocode for stratified sampling at this point\n",
    "    \"\"\"\n",
    "    \n",
    "    df_0 = df[ df[target] == 0 ]\n",
    "    df_1 = df[ df[target] == 1 ]\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    I am keeping all the 1 and then taking only a \n",
    "    \"\"\"\n",
    "    \n",
    "    print('df_0.shape ', df_0.shape)\n",
    "    \n",
    "    print('-----')\n",
    "    print(\"Different quartile values for the continuous variable \", attribute, '\\n')\n",
    "    \n",
    "    low = df_0[attribute].quantile(0.00)\n",
    "    print('\\t\\tlow: ', low)\n",
    "    \n",
    "    first_quartile = df_0[attribute].quantile(0.25)\n",
    "    print('\\t\\tfirst quartile: ', first_quartile)\n",
    "    \n",
    "    median = df_0[attribute].quantile(0.50)\n",
    "    print('\\t\\tmedian: ', median)\n",
    "    \n",
    "    third_quartile = df_0[attribute].quantile(0.75) \n",
    "    print('\\t\\tthird_quartile: ', third_quartile)\n",
    "    \n",
    "    high = df_0[attribute].quantile(1.00)\n",
    "    print('\\t\\thigh: ', high)\n",
    "    \n",
    "    \n",
    "    # Filter tuples in df_0 below the first quartile\n",
    "    df_25 = df_0[   df_0[attribute ] < df_0[attribute].quantile(0.25)    ]\n",
    "    \n",
    "    \n",
    "    df_50 = df_0[ (df_0[attribute].quantile(0.25) <= df_0[attribute]) & ( df_0[attribute] < df_0[attribute].quantile(0.50) )]\n",
    "    \n",
    "\n",
    "    \n",
    "    df_75 = df_0[ (df_0[attribute].quantile(0.50) <= df_0[attribute])  & ( df_0[attribute] < df_0[attribute].quantile(0.75) )]\n",
    "    \n",
    "    df_100 =  df_0[( df_0[attribute].quantile(0.75) <= df_0[attribute] )]    #(df_0[attribute].quantile(0.75) <= df_0[df[attribute] ) \n",
    "\n",
    "    \n",
    "    print('1st df_0, ', df_25.shape)\n",
    "    print('2nd df_0, ', df_50.shape)\n",
    "    print('3rd df_0, ', df_75.shape)\n",
    "    print('4th df_0, ', df_100.shape)\n",
    "    #print(df_below_first_quartile.shape)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Take a samples of each interval \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    SAMPLE_SIZE_0 = math.ceil(df_1.shape[0] * 4) \n",
    "    \n",
    "    quartile_sample_size = math.floor( SAMPLE_SIZE_0 / 4 ) \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('df_1.shape : ', df_1.shape[0] ) \n",
    "    print('SAMPLE_SIZE_0', SAMPLE_SIZE_0)    \n",
    "    print('quartile_sample_size', quartile_sample_size)    \n",
    "    \n",
    "    \n",
    "    # Got all the info to .sample rn\n",
    "    \n",
    "    \n",
    "    df_25_sampled = df_25.sample(n = quartile_sample_size)\n",
    "    df_50_sampled = df_50.sample(n = quartile_sample_size)\n",
    "    df_75_sampled = df_75.sample(n = quartile_sample_size)\n",
    "    df_100_sampled = df_100.sample(n =quartile_sample_size)\n",
    "    \n",
    "    \n",
    "    print(df_25_sampled.shape)\n",
    "    print(df_50_sampled.shape)\n",
    "    print(df_75_sampled.shape)\n",
    "    print(df_100_sampled.shape)\n",
    "    \n",
    "    #print(df_0_25_sample_size)\n",
    "    \n",
    "    #df_0_50_sample_size = \n",
    "    #df_0_75_sample_size = \n",
    "    #df_0_100_sample_size = df.\n",
    "    \n",
    "    \n",
    "    df_sampled = pd.concat([df_25_sampled, df_50_sampled, df_75_sampled, df_100_sampled, df_1], axis=0) \n",
    "    \n",
    "    \n",
    "    print('In original dataset:', np.unique(target_attribute, return_counts=True))\n",
    "    #print('In sampled dataset: ', np.unique(df_sampled['isFraud'], return_counts=True)) \n",
    "    \n",
    "    \"\"\"\n",
    "    - At this point, I have got the stratified sampled data that I want \n",
    "    - \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print('In new, sampled dataset', df_sampled.shape)\n",
    "    \n",
    "    #return df_sampled.sample(frac=1).reset_index(drop=True) \n",
    "    \n",
    "    \n",
    "    df_sampled = df_sampled.sample(frac=1, random_state=1)\n",
    "    \n",
    "    examples_a_sampled = df_sampled.iloc[:, 0]\n",
    "    target_a_sampled = df_sampled.iloc[:, -1]\n",
    "    \n",
    "    \n",
    "    return examples_a_sampled, target_a_sampled\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "50d05017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tattribute and target name :  TransactionAmt ,  isFraud\n",
      "Columns of new df formed Index(['TransactionAmt', 'isFraud'], dtype='object')\n",
      "df_0.shape  (455902, 2)\n",
      "-----\n",
      "Different quartile values for the continuous variable  TransactionAmt \n",
      "\n",
      "\t\tlow:  0.251\n",
      "\t\tfirst quartile:  43.97\n",
      "\t\tmedian:  68.5\n",
      "\t\tthird_quartile:  120.0\n",
      "\t\thigh:  31940.0\n",
      "1st df_0,  (113819, 2)\n",
      "2nd df_0,  (113898, 2)\n",
      "3rd df_0,  (114198, 2)\n",
      "4th df_0,  (113987, 2)\n",
      "df_1.shape :  16530\n",
      "SAMPLE_SIZE_0 66120\n",
      "quartile_sample_size 16530\n",
      "(16530, 2)\n",
      "(16530, 2)\n",
      "(16530, 2)\n",
      "(16530, 2)\n",
      "In original dataset: (array([0, 1]), array([455902,  16530]))\n",
      "In new, sampled dataset (82650, 2)\n"
     ]
    }
   ],
   "source": [
    "examples_a_sampled, target_a_sampled = sample_continuous_attribute(examples_a, target_attribute, sampling_threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "85ab44ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49590, 66120)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16530 * 3, 16530 * 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5177e1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455902"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "113819+ 113898 + 114198 + 113987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "8530879c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66120"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16530*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7c6f536d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36822     0\n",
       "206968    1\n",
       "103080    0\n",
       "385194    0\n",
       "333127    1\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([66120, 16530]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(target_a_sampled.tail())\n",
    "display(np.unique(target_a_sampled, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "8e6517e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain_for_continuous_attribute( examples_a, target_attribute, impurity='entropy'): # 02/28/2024 This stays. Fix this \n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        examples_a : The attribute column whose feature is to be calculated. The name is passed \n",
    "            type: Pandas Series \n",
    "            \n",
    "        target_attribute : Attribute whose value is to be predicted by tree. The name is passed \n",
    "            type: Pandas Series  \n",
    "        \n",
    "        \n",
    "        impurity_measure : gini/entropy \n",
    "            type: string\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        scalar real number  \n",
    "            \n",
    "        \n",
    "        \n",
    "        self.information_gain( examples[a], target_attribute, 'entropy') # examples is pd df\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"\\t\\t--> In method: information_gain_for_continuous_attribute \")\n",
    "        \n",
    "        df_cont = pd.concat([ examples_a, target_attribute ], axis=1)\n",
    "        attr = examples_a.name\n",
    "        targ = target_attribute.name\n",
    "        impurity_parent_node = compute_impurity_by_label(target_attribute, impurity=impurity)\n",
    "        N = examples_a.shape[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #sys.exit(0)\n",
    "        print('number of attribute instances in parent node: ', N)\n",
    "        print('impurity_parent_node : ', impurity_parent_node)\n",
    "        \n",
    "        \n",
    "        print('Feature/attribute name: ', attr)\n",
    "        \n",
    "        \n",
    "        highest_info_gain = float('-inf')\n",
    "        p_ = None # the percentile w/ highest info gain \n",
    "        perc_value \n",
    "        # The percentles where we are splitting- \n",
    "        percentiles = [ 0.25, 0.375, .50, 0.625, 0.75]\n",
    "        \n",
    "        #sys.exit(0)\n",
    "        for p in percentiles: \n",
    "            print('------')\n",
    "            print(p)\n",
    "            percentile_value = examples_a.quantile(p)\n",
    "            print('percentile_value : ', percentile_value)\n",
    "            \n",
    "        \n",
    "            # get the dataset above and below this percentile \n",
    "            df_below = df_cont[ df_cont[attr] < percentile_value ]\n",
    "            df_above = df_cont[ df_cont[attr] >= percentile_value]\n",
    "            \n",
    "            print('percentile value : ', p)\n",
    "            print('df_below.shape : ', df_below.shape)\n",
    "            print('df_above.shape : ', df_above.shape)\n",
    "            \n",
    "            print('labels below percentile: ', np.unique( df_below[targ], return_counts=True ))  \n",
    "            print('labels above percentile: ', np.unique( df_above[targ], return_counts=True )) \n",
    "            \n",
    "            \n",
    "            impurity_below = compute_impurity_by_label(df_below[targ], impurity=impurity)\n",
    "            impurity_above = compute_impurity_by_label(df_above[targ], impurity=impurity)\n",
    "            \n",
    "            \n",
    "            print('impurity_below : ',impurity_below )\n",
    "            print('impurity above : ', impurity_above )\n",
    "            \n",
    "            n_below = df_below.shape[0]\n",
    "            n_above = df_above.shape[0]\n",
    "            \n",
    "            print('n_below : ', n_below)\n",
    "            print('n_above : ', n_above)\n",
    "            \n",
    "            info_gain = impurity_parent_node - float( (n_below/N) * impurity_below  ) - float( (n_above/N) * impurity_above  )\n",
    "            \n",
    "            \n",
    "            if info_gain > highest_info_gain:\n",
    "                highest_info_gain = info_gain \n",
    "                p_ = p \n",
    "                perc_value = \n",
    "            \n",
    "            print(\"info_gain :\", info_gain)\n",
    "            \n",
    "            print('=====')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            - Notice that the featue column rn holds the \"technically\" the same value in either below and above \n",
    "            - Use the info gain by label \n",
    "            \"\"\"\n",
    "        print('Interval w/ highest info gain ' , p_) \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #sys.exit(0)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "0997e47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.5"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50+12.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "c8647721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t--> In method: information_gain_for_continuous_attribute \n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 82650\n",
      "0.8000000000000000444089209850062616169452667236328125\n",
      "0.200000000000000011102230246251565404236316680908203125\n",
      "\t\tlabel_fractions:  [0.8, 0.2]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [66120 16530]\n",
      "\t\tFractions of different labels:  [0.8 0.2]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.7219280948873623\n",
      "number of attribute instances in parent node:  82650\n",
      "impurity_parent_node :  0.7219280948873623\n",
      "Feature/attribute name:  TransactionAmt\n",
      "------\n",
      "0.25\n",
      "percentile_value :  40.205\n",
      "percentile value :  0.25\n",
      "df_below.shape :  (20663, 2)\n",
      "df_above.shape :  (61987, 2)\n",
      "labels below percentile:  (array([0, 1]), array([15839,  4824]))\n",
      "labels above percentile:  (array([0, 1]), array([50281, 11706]))\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 20663\n",
      "0.766539224701156651775590944453142583370208740234375\n",
      "0.233460775298843348224409055546857416629791259765625\n",
      "\t\tlabel_fractions:  [0.7665392247011567, 0.23346077529884335]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [15839  4824]\n",
      "\t\tFractions of different labels:  [0.76653922 0.23346078]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.783995598798953\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 61987\n",
      "0.81115395163502024278301405502134002745151519775390625\n",
      "0.18884604836497975721698594497865997254848480224609375\n",
      "\t\tlabel_fractions:  [0.8111539516350202, 0.18884604836497976]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [50281 11706]\n",
      "\t\tFractions of different labels:  [0.81115395 0.18884605]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.6990512314162662\n",
      "impurity_below :  0.783995598798953\n",
      "impurity above :  0.6990512314162662\n",
      "n_below :  20663\n",
      "n_above :  61987\n",
      "info_gain : 0.0016402577454037726\n",
      "=====\n",
      "------\n",
      "0.375\n",
      "percentile_value :  55.0\n",
      "percentile value :  0.375\n",
      "df_below.shape :  (30895, 2)\n",
      "df_above.shape :  (51755, 2)\n",
      "labels below percentile:  (array([0, 1]), array([24305,  6590]))\n",
      "labels above percentile:  (array([0, 1]), array([41815,  9940]))\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 30895\n",
      "0.78669687651723574361994906212203204631805419921875\n",
      "0.213303123482764200868899706620140932500362396240234375\n",
      "\t\tlabel_fractions:  [0.7866968765172357, 0.2133031234827642]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [24305  6590]\n",
      "\t\tFractions of different labels:  [0.78669688 0.21330312]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.7477492800431369\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 51755\n",
      "0.80794126171384406109865494727273471653461456298828125\n",
      "0.19205873828615593890134505272726528346538543701171875\n",
      "\t\tlabel_fractions:  [0.8079412617138441, 0.19205873828615594]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [41815  9940]\n",
      "\t\tFractions of different labels:  [0.80794126 0.19205874]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.7057583695108105\n",
      "impurity_below :  0.7477492800431369\n",
      "impurity above :  0.7057583695108105\n",
      "n_below :  30895\n",
      "n_above :  51755\n",
      "info_gain : 0.00047330455506089386\n",
      "=====\n",
      "------\n",
      "0.5\n",
      "percentile_value :  69.2\n",
      "percentile value :  0.5\n",
      "df_below.shape :  (41320, 2)\n",
      "df_above.shape :  (41330, 2)\n",
      "labels below percentile:  (array([0, 1]), array([33327,  7993]))\n",
      "labels above percentile:  (array([0, 1]), array([32793,  8537]))\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 41320\n",
      "0.8065585672797677130319016214343719184398651123046875\n",
      "0.193441432720232342479249609823455102741718292236328125\n",
      "\t\tlabel_fractions:  [0.8065585672797677, 0.19344143272023234]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [33327  7993]\n",
      "\t\tFractions of different labels:  [0.80655857 0.19344143]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.708615412768238\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 41330\n",
      "0.79344301959835472626281216435017995536327362060546875\n",
      "0.2065569804016453014927634512787335552275180816650390625\n",
      "\t\tlabel_fractions:  [0.7934430195983547, 0.2065569804016453]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [32793  8537]\n",
      "\t\tFractions of different labels:  [0.79344302 0.20655698]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.7348497816664793\n",
      "impurity_below :  0.708615412768238\n",
      "impurity above :  0.7348497816664793\n",
      "n_below :  41320\n",
      "n_above :  41330\n",
      "info_gain : 0.00019391059384521458\n",
      "=====\n",
      "------\n",
      "0.625\n",
      "percentile_value :  104.0\n",
      "percentile value :  0.625\n",
      "df_below.shape :  (51630, 2)\n",
      "df_above.shape :  (31020, 2)\n",
      "labels below percentile:  (array([0, 1]), array([41458, 10172]))\n",
      "labels above percentile:  (array([0, 1]), array([24662,  6358]))\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 51630\n",
      "0.80298276196010076599662852459005080163478851318359375\n",
      "0.197017238039899289514522706667776219546794891357421875\n",
      "\t\tlabel_fractions:  [0.8029827619601008, 0.1970172380398993]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [41458 10172]\n",
      "\t\tFractions of different labels:  [0.80298276 0.19701724]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.7159223093574179\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 31020\n",
      "0.795035460992907783150940304039977490901947021484375\n",
      "0.2049645390070921890934840803311089985072612762451171875\n",
      "\t\tlabel_fractions:  [0.7950354609929078, 0.2049645390070922]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [24662  6358]\n",
      "\t\tFractions of different labels:  [0.79503546 0.20496454]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.7317467358339719\n",
      "impurity_below :  0.7159223093574179\n",
      "impurity above :  0.7317467358339719\n",
      "n_below :  51630\n",
      "n_above :  31020\n",
      "info_gain : 6.659969446110026e-05\n",
      "=====\n",
      "------\n",
      "0.75\n",
      "percentile_value :  136.0\n",
      "percentile value :  0.75\n",
      "df_below.shape :  (61982, 2)\n",
      "df_above.shape :  (20668, 2)\n",
      "labels below percentile:  (array([0, 1]), array([50496, 11486]))\n",
      "labels above percentile:  (array([0, 1]), array([15624,  5044]))\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 61982\n",
      "0.8146881352650769958501086875912733376026153564453125\n",
      "0.1853118647349230319054669280376401729881763458251953125\n",
      "\t\tlabel_fractions:  [0.814688135265077, 0.18531186473492303]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [50496 11486]\n",
      "\t\tFractions of different labels:  [0.81468814 0.18531186]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.6915605706861123\n",
      "--> In method: compute_impurity_by_label \n",
      "\t\t Number of rows in attribute param: 20668\n",
      "0.75595122895297073295495238198782317340373992919921875\n",
      "0.244048771047029211533896386754349805414676666259765625\n",
      "\t\tlabel_fractions:  [0.7559512289529707, 0.2440487710470292]\n",
      "\t\tDifferent label values collected:  [0 1]\n",
      "\t\tDifferent label counts colleceted:  [15624  5044]\n",
      "\t\tFractions of different labels:  [0.75595123 0.24404877]\n",
      "-------------\n",
      "\n",
      "\n",
      "\n",
      "-------------\t\t\\entropy =  0.8017086624957539\n",
      "impurity_below :  0.6915605706861123\n",
      "impurity above :  0.8017086624957539\n",
      "n_below :  61982\n",
      "n_above :  20668\n",
      "info_gain : 0.002823171369771782\n",
      "=====\n",
      "Interval w/ highest info gain  0.75\n"
     ]
    }
   ],
   "source": [
    "information_gain_for_continuous_attribute( examples_a_sampled, target_a_sampled, impurity='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "90d99f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cont_info_gain(nv, df) output: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "a4309de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472432"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6337e4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get the current directory\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m current_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# List all files and folders in the current directory\u001b[39;00m\n\u001b[1;32m      5\u001b[0m files_and_folders \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(current_dir)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de322482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "- Along the pipeline, keep the dataframe as pandas for as long as possible. \n",
    "\n",
    "- \n",
    "\n",
    "- \n",
    "\n",
    "- \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ID3_1: \n",
    "    \n",
    "    def __init__(self, df, attributes):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        examples : training examples\n",
    "        \n",
    "        target_attribute : attriburte whose value is to be predicted by tree \n",
    "            \n",
    "        attributes : list of other attributes to be tested \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Returns a decision tree that correctly classsifies the examples\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        examples = df[:, 0:-1]\n",
    "        target_attribute = df[:, -1]\n",
    "        \n",
    "        # 1. create  a root for the tree\n",
    "        root = [] \n",
    "        \n",
    "        # 2 and 3. All examples have same label -> return single node with that label\n",
    "        target_values , target_counts = np.unique(target_attribute, return_counts=True)\n",
    "        \n",
    "        if len(target_values) ==1: \n",
    "            \n",
    "            return root, target_values[0] # I am not sure how this will look  \n",
    "        \n",
    "        \n",
    "        \n",
    "        # 4.attributes is empty \n",
    "            # then return single-node tree root, \n",
    "            # with most common label in target_attribute in examples\n",
    "        \n",
    "        if len(attributes) == 0: \n",
    "            # Find the most frequent target value\n",
    "            target_value, target_count = np.unique(target_attribute, return_counts=True)\n",
    "            most_frequent_value = target_value[np.argmax(target_count)]\n",
    "            \n",
    "            return root, most_frequent_value\n",
    "        \n",
    "        # 5. Do this - this is where is information gain is calculated \n",
    "        \"\"\"\n",
    "        Find the information_gain for each attribute to decide the best att\n",
    "        \n",
    "        - A is the variable with the best attribute that best classifies the examples \n",
    "        - examples_vi \n",
    "        - \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        A = None\n",
    "        \n",
    "        highest_info_gain = -100000.0\n",
    "        \n",
    "        for a in attributes: # find the attribute with the highest information gain \n",
    "            \n",
    "            \"\"\"\n",
    "            There needs to be a methods to decide if the attribute is discrete or continuous.\n",
    "            For now, assume all are discrete. \n",
    "            \"\"\"\n",
    "            \n",
    "            #info_gain = self.information_gain( examples[a], target_attribute, 'entropy') # examples is pd df\n",
    "            info_gain = self.information_gain_for_discrete_attribute(examples[a], target_attribute, 'entropy')        \n",
    "            \n",
    "            if info_gain > highest_info_gain: \n",
    "                A = a\n",
    "                highest_info_gain = info_gain \n",
    "        \n",
    "        \n",
    "        print('A w/ highest info gain : ', A)\n",
    "        print('highest_info_gain : ', highest_info_gain)\n",
    "        \n",
    "        \n",
    "        # set root to A \n",
    "        root.append(A) \n",
    "\n",
    "        # get the unique values in A\n",
    "        vi_list_np = np.unique(examples[A]) # examples is pandas df\n",
    "        vi_with_root = [] \n",
    "        \n",
    "\n",
    "        vi_count = 0 \n",
    "            \n",
    "        \n",
    "        for vi in vi_list_np : \n",
    "\n",
    "            vi_count = vi_count+1 \n",
    "            \n",
    "            # Add a new branch below root, corresponding to the test A = v_i \n",
    "            vi_with_root.append(A+'->'+vi) # a list \n",
    "            root.append( vi_with_root )\n",
    "            \n",
    "            # Let Examples_vi be the subest of examples that have value v_i for A \n",
    "            examples_vi  = examples[ examples[A] == vi ]\n",
    "            \n",
    "    \n",
    "        \n",
    "            # If examples_vi is empty : What I understand from this is that there is not tuple \n",
    "            \"\"\"\n",
    "            When examples_vi is empty, it means there is not tuple. But, \n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            if examples_vi.empty: \n",
    "                \n",
    "                # Then below this new branch add a leaf node with label = most common value of Target_attribute in Examples\n",
    "                target_value, target_count = np.unique(target_attribute, return_counts=True)\n",
    "                most_frequent_value = target_value[np.argmax(target_count)]\n",
    "                \n",
    "                return root, most_frequent_value\n",
    "                \n",
    "                \n",
    "            else: #  \n",
    "                ID3(df[ df[ A ] == vi], attributes.remove(A))\n",
    "                \n",
    "            \n",
    "            vi_with_root = [] \n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            I am thinking of using dictionary as for the mean branching an attribute\n",
    "            \n",
    "            - Root is a list\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "        #A = None \n",
    "        #examples_vi = [] #None \n",
    "        \n",
    "        #branches = [] # the branches of the tree\n",
    "        \n",
    "        \n",
    "        #if len( branches_vi) == 0: \n",
    "            # Then below this new branch add a  leaf node with label = most common value of Target_attribute in Examples\n",
    "        \n",
    "        \n",
    "        #else:  # below this new branch add the subtree \n",
    "        #    ID3( examples_vi,  target_attribute, )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def information_gain( examples, target_attribute, attribute, impurity='gini'): \n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        examples : numpy array \n",
    "            the feature columns whose information gain is to be calculated \n",
    "            \n",
    "        target_attribute : numpy array \n",
    "            the target label - y\n",
    "            \n",
    "        attribute : string \n",
    "            the attribute whose info gain to be calculated \n",
    "        \n",
    "        impurity : string \n",
    "            the impurity measure - gini or entropy \n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy scalar real number \n",
    "\n",
    "        \"\"\"\n",
    "        return -1 \n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "      \n",
    "        \n",
    "    def compute_impurity_by_label(self, attribute, impurity='gini'): # Impurity of the total dataset : DONE\n",
    "        \n",
    "        \"\"\"\n",
    "        FEATURES: \n",
    "        \n",
    "        attribute : pandas df\n",
    "            the column whose entropy is to be calculated\n",
    "        \n",
    "        impurity : string \n",
    "            the impurity measure used- gini or entropty \n",
    "        \n",
    "        \n",
    "        Returns \n",
    "            np real scalar number \n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "        # get the total number of instances/rows in the dataset\n",
    "        N = attribute.shape[0]\n",
    "        \n",
    "        print('\\t\\t Number of rows in attribute param:', N)\n",
    "        #sys.exit(0)\n",
    "    \n",
    "        # get the count\n",
    "        label_values, label_counts = np.unique(attribute, return_counts=True)\n",
    "        label_fractions = []\n",
    "    \n",
    "    \n",
    "        # get the fractions for the each of the labels- better to use loop be cause there can be more than two labels\n",
    "    \n",
    "        for count in label_counts :\n",
    "            print(Decimal(count/N)) \n",
    "            \n",
    "            result_float = float( count/ Decimal(N) )\n",
    "            \n",
    "            label_fractions.append( result_float  )\n",
    "    \n",
    "    \n",
    "        print('\\t\\tlabel_fractions: ',label_fractions)\n",
    "        \n",
    "        label_fractions = np.array( label_fractions )\n",
    "        print('\\t\\tDifferent label values collected: ', label_values)\n",
    "        print('\\t\\tDifferent label counts colleceted: ', label_counts)\n",
    "        print('\\t\\tFractions of different labels: ', label_fractions)\n",
    "    \n",
    "    \n",
    "        # write a subroutine for entropy\n",
    "        if impurity=='entropy':\n",
    "            #return  - np.sum ( label_fractions * np.log2(  label_fractions ) ) # This returns the complete entropy \n",
    "            print('-------------\\n\\n\\n')\n",
    "            #print(\"\\t\\t\\tInside impurity=entropy\",  -1 * label_fractions * np.log2(label_fractions) ) \n",
    "    \n",
    "            print(\"-------------\\t\\t\\tnp.sum = \", -np.sum(  label_fractions * np.log2(label_fractions) ) )\n",
    "            \n",
    "            \n",
    "            return -np.sum(  label_fractions * np.log2(label_fractions) )\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "        # write a subroutine for gini\n",
    "        elif impurity=='gini':  \n",
    "    \n",
    "          return 1 - np.sum(  np.square( label_fractions )   ) # 1 - sum of elementwise fraction #This returns the complete gini\n",
    "    \n",
    "    \n",
    "        else :\n",
    "    \n",
    "            print(\"ERROR: impurity metric can be either of gini or entropy.\")\n",
    "            return -1 \n",
    "        \n",
    "        \n",
    "    def information_gain_for_discrete_attribute(self, examples_a, target_attribute, impurity='entropy'): # 02/28/2024 This stays. Fix this \n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        examples_a : the attribute column whose feature is to be calculated \n",
    "            type: Pandas Series \n",
    "            \n",
    "        target_attribute : attribute whose value is to be predicted by tree \n",
    "            type: Pandas Series  \n",
    "        \n",
    "        attribute : attribute/column name for examples_a\n",
    "            type: string\n",
    "        \n",
    "        impurity_measure : gini/entropy \n",
    "            type: string\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        scalar real number  \n",
    "            \n",
    "        \n",
    "        \n",
    "        self.information_gain( examples[a], target_attribute, 'entropy') # examples is pd df\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        #impurity_for_target_attribute = self.compute_impurity_for_discrete_attribute(target_attribute, impurity=impurity)\n",
    "        \n",
    "        \n",
    "        # get the unique values in examples_a\n",
    "        examples_a_values = np.unique(examples_a)\n",
    "        \n",
    "        N = examples_a.shape[0]\n",
    "        \n",
    "        result = self.compute_impurity_by_label(  attribute=target_attribute , impurity=impurity)\n",
    "        \n",
    "        print( '\\t\\t\\tresult after initialization : ', result) # ok \n",
    "        \n",
    "        #sys.exit(0)\n",
    "        for a in examples_a_values: \n",
    "            \n",
    "            # get the subset of examples_a and corresponding tuple in target_attribute\n",
    "            #examples_a[attribute]\n",
    "            #print( examples_a[examples_a==a])\n",
    "            #print('-----')\n",
    "            #print('feature subset shape:\\n', examples_a[examples_a==a].shape)\n",
    "            #print('-----')\n",
    "            \n",
    "            #print( 'target subset shape:\\n', target_attribute[examples_a==a].shape )\n",
    "        \n",
    "            \n",
    "            #examples_a_subset = np.array( examples_a[examples_a==a] ) \n",
    "            \"\"\"\n",
    "            I don't need the line above rn\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            #target_a_subset = np.array( target_attribute[examples_a==a] ) # converting to np for faster computation\n",
    "            \n",
    "            n = target_attribute[examples_a==a].shape[0]\n",
    "            #compute_impurity_by_label(  np.array( target_attribute[examples_a==a] ), impurity=impurity)\n",
    "            \n",
    "            \n",
    "            prob_float = float( n/ Decimal(N) )\n",
    "            \n",
    "            \n",
    "            impurity_a = self.compute_impurity_by_label( target_attribute[examples_a==a] , impurity=impurity) * prob_float\n",
    "            \n",
    "            result = result - impurity_a\n",
    "            \n",
    "            print('\\t\\t---------------\\t\\t\\n')\n",
    "            \n",
    "            \n",
    "            \n",
    "            print('\\t\\t\\t--- final info gain : ', result )\n",
    "            \n",
    "        return result # returns a scalar real number         \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
